{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 53,578\n",
      "Trainable params: 53,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "# Load its data into training and test vectors\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# Collect feature size info\n",
    "imgSize0=len(x_train[0])\n",
    "imgSize1=len(x_train[0][0])\n",
    "numPixels=imgSize0*imgSize1\n",
    "numTrainImages=len(x_train)\n",
    "featureShape=(None, imgSize0,imgSize1,1)\n",
    "\n",
    "# Clearup everything before running\n",
    "tf.keras.backend.clear_session()\n",
    "# Create model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu', input_shape=(28, 28, 1)\n",
    "    ),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu',),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "# Build model and print summary\n",
    "model.build(input_shape=featureShape)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(x_train.astype('float32')).batch(1).take(100):\n",
    "      yield [input_value]   \n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce full-int8 quantization (except inputs/outputs which are always float)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_data_gen\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# tflite_model = converter.convert()\n",
    "model_length = open(\"model.tflite\", \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i 'model.tflite' > 'model.cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read in the file\n",
    "with open('model.cc', 'r') as file :\n",
    "  filedata = file.read()\n",
    "\n",
    "#include \"model.h\"\n",
    "# Replace the target string\n",
    "filedata = filedata.replace('unsigned char', 'alignas(16) const unsigned char' )\n",
    "filedata = filedata.replace('unsigned int', 'const int' )\n",
    "filedata = '#include \"model.h\" \\n \\n' \\\n",
    "    + \"// Keep model aligned to 8 bytes to guarantee aligned 64-bit accesses. \\n\\n\" \\\n",
    "    + filedata\n",
    "# Write the file out again\n",
    "with open('model.cc', 'w') as file:\n",
    "  file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_h_file = open('model.h', 'r') \n",
    "old_lines = read_h_file.readlines()\n",
    "new_lines = []    \n",
    "for line in old_lines:\n",
    "    if \"model_len\" in line:\n",
    "        new_lines.append(\"const int model_len = {};\".format(model_length) )\n",
    "    else:\n",
    "        new_lines.append(line)\n",
    "# print (new_lines)\n",
    "read_h_file.close()\n",
    "\n",
    "write_header_file = open('model.h', 'w') \n",
    "write_header_file.writelines(new_lines)\n",
    "write_header_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

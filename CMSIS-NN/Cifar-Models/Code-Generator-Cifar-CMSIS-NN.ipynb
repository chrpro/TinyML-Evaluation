{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model convertion to CMSIS-NN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (50000, 1)\n",
      "Shape after one-hot encoding:  (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from  keras.utils import np_utils\n",
    "\n",
    "\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# # building the input vector from the 32x32 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                11530     \n",
      "=================================================================\n",
      "Total params: 21,674\n",
      "Trainable params: 21,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "196/196 [==============================] - 21s 107ms/step - loss: 1.8212 - accuracy: 0.3480 - val_loss: 1.5910 - val_accuracy: 0.4431\n",
      "Epoch 2/15\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 1.5143 - accuracy: 0.4645 - val_loss: 1.4437 - val_accuracy: 0.4900\n",
      "Epoch 3/15\n",
      "160/196 [=======================>......] - ETA: 3s - loss: 1.3838 - accuracy: 0.5139"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu',),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(X_train, Y_train, batch_size=256, epochs=15, validation_data=(X_test, Y_test))\n",
    "model.save('cifar.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model,\n",
    "    show_layer_names=False, show_shapes=True, rankdir='LR', expand_nested=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate C-code  for cmsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for fast quantization! Please check more advance methods\n",
    "#To improve: you need to refine the activations of each layer!\n",
    "\n",
    "fp = 'keras-weights.h'\n",
    "print('Write weights and net parameters into:' + fp)\n",
    "search_range=3\n",
    "\n",
    "with open(fp, 'w') as f:\n",
    "    wt_int_bits={}\n",
    "    wt_dec_bits={}\n",
    "    for layer in model.layers:\n",
    "\n",
    "        weightsArray = layer.get_weights()\n",
    "\n",
    "        write_name = layer.name.upper()\n",
    "        \n",
    "        idx =0\n",
    "        bias = '_WT'\n",
    "        for weight in weightsArray:\n",
    "            print(weight.shape)\n",
    "            #Find min and max of w's\n",
    "            w_max = weight.max()\n",
    "            w_min = weight.min() \n",
    "            \n",
    "            int_bits = int(np.ceil(np.log2(max(abs(w_min),abs(w_max)))))\n",
    "            frac_bits = 7 - int_bits#remaining bits are fractional bits (1-bit for sign)\n",
    "\n",
    "\n",
    "            #floating point weights are scaled and rounded to [-128,127], which are used in \n",
    "            quant_weight = np.clip(np.round(weight*(2**frac_bits)), -128, 127)\n",
    "\n",
    "    \n",
    "            f.write('#define '+write_name+bias+' {')\n",
    "            np.transpose(quant_weight).tofile(\n",
    "                f, sep=\", \", format=\"%d\")\n",
    "            f.write('}\\n')\n",
    "            if 'BIAS' in bias:\n",
    "                f.write('#define '+write_name+'_BIAS_LSHIFT '+str(frac_bits)+'\\n')\n",
    "            else:\n",
    "                f.write('#define '+write_name+'_OUT_RSHIFT '+str(frac_bits)+'\\n')\n",
    "            bias ='_BIAS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'keras-parameters.h'\n",
    "print('Generating parameter file: '+file_name)\n",
    "f=open(file_name,'w')\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer_no=model.layers.index(layer)\n",
    "    if(layer_no>0):\n",
    "        prev_layer=model.layers[layer_no-1]\n",
    "\n",
    "    if layer.__class__.__name__=='Conv2D':\n",
    "        LAYER=layer.name.upper()\n",
    "        f.write(\"#define \"+LAYER+\"_IN_DIM \"+str(layer.input_shape[1])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_IN_CH \"+str(layer.input_shape[3])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_KER_DIM \"+str(layer.kernel_size[1])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_PAD \"+str(0)+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_STRIDE \"+str(layer.strides[1])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_OUT_CH \"+str(layer.output_shape[3])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_OUT_DIM \"+str(layer.output_shape[2])+\"\\n\\n\") \n",
    "\n",
    "\n",
    "    elif layer.__class__.__name__=='MaxPooling2D':\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_IN_DIM \"+str(layer.input_shape[1])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_IN_CH \"+str(layer.input_shape[3])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_KER_DIM \"+str(layer.pool_size[1])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_PAD \"+str(0)+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_STRIDE \"+str(layer.strides[1])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_OUT_DIM \"+str(layer.output_shape[2])+\"\\n\\n\")\n",
    "    elif  layer.__class__.__name__=='Dense':\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_DIM \"+str(layer.input_shape[1])+\"\\n\")\n",
    "        f.write(\"#define \"+layer.name.upper()+\"_OUT \"+str(layer.output_shape[1])+\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = 'keras-dnn.h'\n",
    "print('Generating file: '+file_name)\n",
    "f=open(file_name,'w')\n",
    "f.write('\\\n",
    "#include \"keras-weights.h\"\\n\\\n",
    "#include \"keras-parameters.h\"\\n\\\n",
    "uint8_t run_nn(q7_t* input_data);\\n\\n\\\n",
    "')\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.__class__.__name__=='Conv2D':\n",
    "        f.write(\"static q7_t \"+layer.name+\"_wt[\"+layer.name.upper()+\"_IN_CH*\"+layer.name.upper()+\"_KER_DIM*\"+\\\n",
    "                layer.name.upper()+\"_KER_DIM*\"+layer.name.upper()+\"_OUT_CH] = \"+layer.name.upper()+\"_WT;\\n\")\n",
    "        f.write(\"static q7_t \"+layer.name+\"_bias[\"+layer.name.upper()+\"_OUT_CH] = \"+layer.name.upper()+\"_BIAS;\\n\")\n",
    "    elif layer.__class__.__name__=='Dense':\n",
    "        f.write(\"static q7_t \"+layer.name+\"_wt[\"+layer.name.upper()+\"_DIM *\"+layer.name.upper()+\"_OUT\"+\\\n",
    "                \"] = \"+layer.name.upper()+\"_WT;\\n\" )\n",
    "        f.write(\"static q7_t \"+layer.name+\"_bias[\"+layer.name.upper()+\"_OUT] = \"+\\\n",
    "                layer.name.upper()+\"_BIAS;\\n\\n\")\n",
    "\n",
    "\n",
    "conv_Highest_in = 1\n",
    "conv_Highest_out = 1\n",
    "dense_Highest = 1\n",
    "pool_highest = 1\n",
    "\n",
    "for layer in model.layers[0:len(model.layers)]:\n",
    "    if \"conv\" in layer.name:        \n",
    "        y = 1\n",
    "        for x in layer.output_shape:\n",
    "            if x is not None:\n",
    "                y = y * x\n",
    "        if y > conv_Highest_out:\n",
    "            conv_Highest_out = y\n",
    "            \n",
    "        y = 1    \n",
    "        for x in layer.input_shape:\n",
    "            if x is not None:\n",
    "                y = y * x\n",
    "        if y > conv_Highest_in:\n",
    "            conv_Highest_in = y    \n",
    "            \n",
    "    if \"dense\"  in layer.name:\n",
    "        y = 1\n",
    "        for x in layer.input_shape:\n",
    "            if x is not None:\n",
    "                y = y * x\n",
    "        if y > dense_Highest:\n",
    "            dense_Highest = y\n",
    "            \n",
    "    if \"max_pooling\" in layer.name:\n",
    "        y = 1\n",
    "        for x in layer.output_shape:\n",
    "            if x is not None:\n",
    "                y = y * x\n",
    "        if y > pool_highest:\n",
    "            pool_highest = y\n",
    "            \n",
    "f.write('static q7_t conv_buffer_out['+str(conv_Highest_out)+'];\\n')\n",
    "f.write('static q15_t conv_buffer_in['+str(conv_Highest_in)+'];\\n')\n",
    "f.write('static q7_t pool_out['+str(pool_highest)+'];\\n')\n",
    "f.write('static q15_t dense_buffer['+str(dense_Highest)+'];\\n')\n",
    "f.write('static q7_t y_out[10];\\n\\n')\n",
    "\n",
    "\n",
    "lay = model.layers[0:len(model.layers)][0].name.upper()\n",
    "\n",
    "\n",
    "f.write('uint8_t run_nn(q7_t* input_data) {\\n')\n",
    "\n",
    "\n",
    "#input convolution need to be RGB -> Cifar images have 3 dim\n",
    "#Flag Input for the first layer\n",
    "Input = 1\n",
    "\n",
    "for layer in model.layers:\n",
    "    LAYER = layer.name.upper()\n",
    "    if layer.__class__.__name__=='Conv2D':\n",
    "        if Input == 1:\n",
    "            conv_func = 'arm_convolve_HWC_q7_RGB'\n",
    "            f.write('  '+conv_func+'(input_data'+', '+LAYER+'_IN_DIM, '+LAYER+\\\n",
    "                            '_IN_CH, '+LAYER.lower()+'_wt, '+LAYER+'_OUT_CH, '+LAYER+'_KER_DIM, '+LAYER+'_PAD, '\\\n",
    "                            +LAYER+'_STRIDE, '+LAYER.lower()+'_bias, '+LAYER+'_BIAS_LSHIFT, '+LAYER+'_OUT_RSHIFT, '\\\n",
    "                            +'conv_buffer_out, '+LAYER+'_OUT_DIM, conv_buffer_in, NULL);\\n')\n",
    "            f.write('  arm_relu_q7('+'conv_buffer_out'+', '+LAYER+'_OUT_DIM*'+LAYER+'_OUT_DIM*'+\\\n",
    "                   LAYER+'_OUT_CH);\\n')\n",
    "            Input = 0\n",
    "        else:\n",
    "            conv_func = 'arm_convolve_HWC_q7_fast'\n",
    "            f.write('  '+conv_func+'(pool_out'+', '+LAYER+'_IN_DIM, '+LAYER+\\\n",
    "                            '_IN_CH, '+LAYER.lower()+'_wt, '+LAYER+'_OUT_CH, '+LAYER+'_KER_DIM, '+LAYER+'_PAD, '\\\n",
    "                            +LAYER+'_STRIDE, '+LAYER.lower()+'_bias, '+LAYER+'_BIAS_LSHIFT, '+LAYER+'_OUT_RSHIFT, '\\\n",
    "                            +'conv_buffer_out, '+LAYER+'_OUT_DIM, conv_buffer_in, NULL);\\n')\n",
    "            f.write('  arm_relu_q7('+'pool_out'+', '+LAYER+'_OUT_DIM*'+LAYER+'_OUT_DIM*'+\\\n",
    "                   LAYER+'_OUT_CH);\\n')\n",
    "            \n",
    "    elif layer.__class__.__name__=='MaxPooling2D':\n",
    "        pool_func='arm_maxpool_q7_HWC'\n",
    "        f.write('  '+pool_func+'('+'conv_buffer_out'+', '+LAYER+'_IN_DIM, '+LAYER+'_IN_CH, '+\\\n",
    "            LAYER+'_KER_DIM, '+LAYER+'_PAD, '+LAYER+'_STRIDE, '+LAYER+'_OUT_DIM, NULL, '+\\\n",
    "            ' pool_out'+');\\n\\n')\n",
    "        \n",
    "    elif  layer.__class__.__name__=='Dense':\n",
    "        f.write('  arm_fully_connected_q7_opt(pool_out,'+LAYER.lower()+'_wt, '+LAYER+'_DIM, '+\\\n",
    "                LAYER+'_OUT, '+LAYER+'_BIAS_LSHIFT, '+\\\n",
    "                LAYER+'_OUT_RSHIFT, '+LAYER.lower()+'_bias, y_out, dense_buffer ) ;\\n')\n",
    "        f.write('  arm_softmax_q7(y_out, 10, y_out); \\n')\n",
    "\n",
    "\n",
    "f.write('  uint32_t index[1];\\n  q7_t result[1];\\n  uint32_t blockSize = sizeof(y_out);\\n'+\\\n",
    "        '  arm_max_q7(y_out, blockSize, result, index);\\n  return index[0];\\n'\n",
    "\n",
    "        )\n",
    "\n",
    "f.write('}')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
